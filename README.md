# AmazonML-DBkaScam


This repository contains the code and resources used by Team **DBkaScam** for the Amazon ML Challenge 2024. Our project involved developing machine learning models to extract entity values from given images in the required format. Our solution got the **6th Rank** and was presented to Amazon Scientists in the Grand Finale!

## Table of Contents

1. [Overview](#overview)
2. [Solution Architecture](#solution-architecture)
3. [Dataset](#dataset)
4. [Preprocessing](#preprocessing)
5. [Modeling](#modeling)
6. [Results](#results)
7. [Conclusion and Future Work](#conclusion-and-future-work)
8. [How to Use](#how-to-use)
9. [Team](#team)

---

### Overview

In this challenge, our goal was to [specific task, e.g., "classify product listings into various categories"]. Our solution leverages [mention any key ML methods like deep learning, ensemble methods, etc.].

<!-- Include the introductory image here from slide 1 of the presentation if applicable. -->

## Solution Architecture

Our approach was designed to optimize both accuracy and efficiency. Key components included:

1. **Data Ingestion and Preprocessing:** Standardizing data formats and removing noise.
2. **Feature Engineering:** Extracting [important features, e.g., "text-based features, numeric indicators"].
3. **Model Selection and Training:** Implemented various ML algorithms such as [specific models used].

### Zero-Shot Prompting
<img width="479" alt="Screenshot 2024-11-05 at 1 48 05 AM" src="https://github.com/user-attachments/assets/28f55996-aff3-47c5-b13d-599978f9984f">


### Few-Shot Prompting
<img width="479" alt="Screenshot 2024-11-05 at 1 48 51 AM" src="https://github.com/user-attachments/assets/2ff2e278-d3ee-4c2a-8f1c-f87869c0de35">

### Fine-Tuning

### Final Ensemble
<img width="532" alt="Screenshot 2024-11-05 at 2 04 33 AM" src="https://github.com/user-attachments/assets/3bd6ec5c-85f7-41df-a5b6-c7129c320b8f">

## Dataset

We utilized the dataset provided by the Amazon ML Challenge, which included [briefly describe data characteristics, e.g., "textual descriptions, numerical indicators"]. Key steps in handling the dataset included:

- **Data Cleaning:** Addressed missing values and standardized entries.
- **Data Augmentation (if any):** Techniques such as [mention techniques] to enhance the training data.

### Preprocessing

To prepare the data, we:

- Applied [specific preprocessing methods like tokenization, normalization].
- Scaled features and encoded categorical variables for model compatibility.

### Modeling

Several models were evaluated to achieve optimal results:

1. **Model 1** - [Brief description, e.g., "Gradient Boosting for handling tabular data."]
2. **Model 2** - [Brief description, e.g., "Transformer-based model for text classification."]
3. **Ensemble Approach** - [Explanation if multiple models were combined.]

<!-- Insert performance comparison or evaluation metrics chart if available in the presentation. -->

### Results

Our final model achieved the following key results on the evaluation metrics:

- **Accuracy:** [xx%]
- **Precision:** [xx%]
- **Recall:** [xx%]
- **F1 Score:** [xx%]

These results demonstrate our model's effectiveness in accurately [task, e.g., classifying product categories].




### Team

- **Arnav Goel**  
  - Institution: [IIIT Delhi]
- **Medha Hira**  
  - Institution: [IIIT Delhi]
- **Mihir Aggarwal**  
  - Institution: [IIT Gandhinagar]
- **AS Poornash**  
  - Institution: [IIT Patna]
