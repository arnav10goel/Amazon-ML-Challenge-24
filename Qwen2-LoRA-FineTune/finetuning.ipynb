{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "!GRADIO_SHARE=1 llamafactory-cli webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_unit_map = {\n",
    "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
    "    'item_weight': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'maximum_weight_recommendation': {'gram',\n",
    "        'kilogram',\n",
    "        'microgram',\n",
    "        'milligram',\n",
    "        'ounce',\n",
    "        'pound',\n",
    "        'ton'},\n",
    "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
    "    'wattage': {'kilowatt', 'watt'},\n",
    "    'item_volume': {'centilitre',\n",
    "        'cubic foot',\n",
    "        'cubic inch',\n",
    "        'cup',\n",
    "        'decilitre',\n",
    "        'fluid ounce',\n",
    "        'gallon',\n",
    "        'imperial gallon',\n",
    "        'litre',\n",
    "        'microlitre',\n",
    "        'millilitre',\n",
    "        'pint',\n",
    "        'quart'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2664285/823481641.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('entity_name').apply(lambda x: x.sample(min(len(x), samples_per_class)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled dataset has 2000 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset\n",
    "dataframe = pd.read_csv('/dataset/test.csv')\n",
    "\n",
    "# Get the unique classes from the 'entity_name' column\n",
    "unique_classes = dataframe['entity_name'].unique()\n",
    "\n",
    "# Define the total number of samples and calculate samples needed per class\n",
    "total_samples = 2000\n",
    "samples_per_class = total_samples // len(unique_classes)\n",
    "\n",
    "# Sample data for each class, limiting the number to 'samples_per_class'\n",
    "sampled_data = dataframe.groupby('entity_name').apply(lambda x: x.sample(min(len(x), samples_per_class)))\n",
    "\n",
    "# Shuffle the dataset to mix samples randomly\n",
    "sampled_data = sampled_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# If the total number of rows is less than 'total_samples' due to unequal class sizes,\n",
    "# sample the remaining required rows from the entire dataset\n",
    "if len(sampled_data) < total_samples:\n",
    "    remaining_samples = total_samples - len(sampled_data)\n",
    "    additional_data = dataframe.sample(remaining_samples, random_state=1)\n",
    "    sampled_data = pd.concat([sampled_data, additional_data])\n",
    "\n",
    "# Function to check if an image is corrupted\n",
    "def is_image_corrupt(image_path):\n",
    "    image_path = \"../test/\" + image_path.split(\"/\")[-1]\n",
    "    try:\n",
    "        # Attempt to open and verify the image\n",
    "        img = Image.open(image_path)\n",
    "        img.verify()  # Force load image data to check for corruption\n",
    "        return False\n",
    "    except (IOError, SyntaxError):\n",
    "        return True\n",
    "\n",
    "# Filter out corrupted images\n",
    "sampled_data = sampled_data[~sampled_data['image_link'].apply(is_image_corrupt)].reset_index(drop=True)\n",
    "\n",
    "# Save the sampled dataset to a CSV file\n",
    "sampled_data.to_csv('sampled_dataset.csv', index=False)\n",
    "print(f\"Sampled dataset contains {len(sampled_data)} rows.\")\n",
    "\n",
    "# Reload the sampled dataset\n",
    "filtered_data = pd.read_csv(\"sampled_dataset.csv\")\n",
    "\n",
    "# Prepare the list for storing instructions and image paths for JSON generation\n",
    "data_list = []\n",
    "\n",
    "for index, row in filtered_data.iterrows():\n",
    "    image_path = \"/../test/\" + row[\"image_link\"].split(\"/\")[-1]\n",
    "    instruction = f\"\"\"<image>Extract the {row['entity_name']} of the item and its unit of measurement from the image,\n",
    "    providing them separately. Ensure that the unit is one of the following: {entity_unit_map[row['entity_name']]}.\"\"\"\n",
    "\n",
    "    # Define the message object for JSON\n",
    "    message_obj = {\n",
    "        \"messages\": [\n",
    "            {'content': instruction, 'role': 'user'},\n",
    "            {'content': \"\", 'role': 'assistant'}\n",
    "        ],\n",
    "        \"images\": [image_path]\n",
    "    }\n",
    "\n",
    "    # Append the message object to the data list\n",
    "    data_list.append(message_obj)\n",
    "\n",
    "# Save the data list as a JSON file\n",
    "with open(\"./data/aml1p.json\", \"w\") as json_file:\n",
    "    json.dump(data_list, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the configuration parameters for the model\n",
    "config_params = {\n",
    "  \"model_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "  # Uncomment and specify path if using a custom adapter: \"adapter_name_or_path\": \"/data/poornash/AML/LLaMA-Factory/qwen2vl_lora_old\",\n",
    "  \"stage\": \"sft\",  # Set stage to 'sft' for supervised fine-tuning\n",
    "  \"do_predict\": True,  # Enable prediction mode\n",
    "  \"do_train\": False,  # Disable training\n",
    "  \"finetuning_type\": \"lora\",  # Specify the finetuning method\n",
    "  \"eval_dataset\": \"aml1p\",  # Evaluation dataset name\n",
    "  \"template\": \"qwen2_vl\",  # Template to use for processing data\n",
    "  \"cutoff_len\": 1024,  # Maximum length of the input sequence\n",
    "  \"max_samples\": 1000000,  # Maximum number of samples to process\n",
    "  \"overwrite_cache\": True,  # Overwrite cache to use fresh data\n",
    "  \"n_shot\": 5,  # Number of examples to use for few-shot learning\n",
    "  \"preprocessing_num_workers\": 16,  # Number of workers for data preprocessing\n",
    "  \"output_dir\": \"/data/poornash/AML/LLaMA-Factory/predictions\",  # Directory to save prediction results\n",
    "  \"overwrite_output_dir\": True,  # Overwrite existing files in the output directory\n",
    "  \"per_device_eval_batch_size\": 6,  # Batch size for evaluation per device\n",
    "  \"predict_with_generate\": True,  # Use generation for prediction\n",
    "  \"ddp_timeout\": 180000000  # Timeout setting for distributed data parallelism\n",
    "}\n",
    "\n",
    "# Save the configuration parameters to a JSON file\n",
    "with open(\"train_qwen2vl.json\", \"w\", encoding=\"utf-8\") as json_file: \n",
    "    json.dump(config_params, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"model_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\", \n",
    "        \"adapter_name_or_path\": \"qwen2vl_lora\", \n",
    "        \"template\": \"qwen2_vl\", \n",
    "        \"finetuning_type\": \"lora\", \n",
    "        \"export_dir\": \"qwen2vl_2b_instruct_lora_merged\", \n",
    "        \"export_size\": 2, \n",
    "        \"export_device\": \"cpu\" \n",
    "        }\n",
    "\n",
    "with open(\"merge_qwen2vl.json\", \"w\", encoding=\"utf-8\") as f: \n",
    "    json.dump(args, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to read a JSONL (JSON Lines) file and load its content into a list\n",
    "def load_jsonl(file_path):\n",
    "    content_list = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            content_list.append(json.loads(line))\n",
    "    return content_list\n",
    "\n",
    "# Example usage\n",
    "jsonl_file_path = '/data/poornash/AML/LLaMA-Factory/predictions/generated_predictions.jsonl'  # Update with the correct file path\n",
    "data_entries = load_jsonl(jsonl_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
